# -*- coding: utf-8 -*-
"""Assignment 2 Code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10h2Q9P_IFJD58OFpE9Kn5dp9S4IsVZMV
"""

# File management

from google.colab import drive
drive.mount('/content/drive/')

cd /content/drive/My Drive/PyTorch/data

# import required modules
import torch
import torchvision
import torchvision.transforms as transforms
from tqdm import tqdm
import numpy as np
from torch.utils.data import random_split
import torch.nn as nn
import torch.nn.functional as F
import datetime
import matplotlib.pyplot as plt
from torchsummary import summary

# set random seed to get reproducible results
random_seed = 42
torch.manual_seed(random_seed)

# Image processing
transform = transforms.Compose([ #torchvision.transforms.RandomHorizontalFlip(p=0.5),
                                #torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.8, 1.2)),
                                transforms.ToTensor(),
                                transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5, 0.5, 0.5])])
print(transform)

# take dataset from folders and split it into train, validation and test sets

# set paths
train_data_dir = '4/train/' # put path of training dataset
val_data_dir = '4/val/' # put path of validation dataset
test_data_dir = '4/test/' # put path of test dataset

# Load Images

trainset = torchvision.datasets.ImageFolder(root= train_data_dir, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=4)

valset = torchvision.datasets.ImageFolder(root= val_data_dir, transform=transform)
valloader = torch.utils.data.DataLoader(valset, batch_size=4,
                                         shuffle=False, num_workers=4)

testset = torchvision.datasets.ImageFolder(root= test_data_dir, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=4)

print('number of images in train set =',len(trainset))
print('trainset class-indices =',trainset.classes)
print('number of images in validation set =',len(valset))
print('trainset class-indices =',valset.classes)
print('number of images in test set =',len(testset))
print('trainset class-indices =',testset.classes)

# Class names
classes = testset.classes
print(classes)

# Base Model
# Let's define the model by extending an ImageClassificationBase class which contains helper methods for training & validation.

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class ImageClassificationBase(nn.Module):
    def training_step(self, batch):
        images, labels = batch 
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        acc = accuracy(out, labels)
        return loss, acc
    
    def validation_step(self, batch):
        images, labels = batch 
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    
    def epoch_end(self, epoch, result,f):
        print("Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, test_loss: {:.4f}, test_acc: {:.4f}".format(
            epoch, result['train_loss'], result['train_acc'], result['val_loss'], result['val_acc']))
        datetime_object = datetime.datetime.now()

        f.write(str(datetime_object)+" - "+"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, test_loss: {:.4f}, test_acc: {:.4f} \n".format(
            epoch, result['train_loss'], result['train_acc'], result['val_loss'], result['val_acc']))

# Helper class and functions to use GPU
# Code to use GPU if available
def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

# Get the device name
device = get_default_device()

# load dataset to GPU
train_loader = DeviceDataLoader(trainloader, device)
val_loader = DeviceDataLoader(valloader, device)
test_loader = DeviceDataLoader(testloader, device)

class Net2(ImageClassificationBase):
    def __init__(self):
        super(Net2, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)
        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5)
        self.fc1 = nn.Linear(in_features=256, out_features=256)
        self.fc2 = nn.Linear(in_features=256, out_features=128)
        self.fc3 = nn.Linear(in_features=128, out_features=33)      # change out_features according to number of classes

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = F.avg_pool2d(x, kernel_size=x.shape[2:])
        x = x.view(x.shape[0], -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# boiler plate code to fit the data
@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(epochs, model, train_loader, val_loader, f, opt_func=torch.optim.SGD, weight_decay = 5e-4):
    history = []
    optimizer = opt_func(model.parameters(), lr=0.001, momentum=0.9, weight_decay=weight_decay)
    for epoch in range(epochs):
        # Training Phase
        train_losses = []
        train_accuracies=[]
        for i, data in enumerate(tqdm(train_loader), 0):
          model.train()
          loss, acc = model.training_step(data)
          train_losses.append(loss)
          train_accuracies.append(acc)
          loss.backward()
          optimizer.step()
          optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_acc'] = torch.stack(train_accuracies).mean().item()
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result, f)
        history.append(result)
    return history

# Print Model Summary
model1 = Net2()
to_device(model1, 'cuda')
summary(model1, (3,84,84))

# train model
f = open("model2_weight_decay=5e-2.txt", "w")
num_epochs = 50
history1 = fit(num_epochs, model1, train_loader, test_loader, f=f, weight_decay=5e-2)
f.close()
torch.save(model1.state_dict(), 'model2_weight_decay=5e-2.pth')

# Print Model Summary
model2 = Net2()
to_device(model2, 'cuda')
summary(model2, (3,84,84))

# train model
f = open("model2_weight_decay=5e-4.txt", "w")
num_epochs = 50
history2 = fit(num_epochs, model2, train_loader, test_loader, f=f, weight_decay=5e-4)
f.close()
torch.save(model2.state_dict(), 'model2_weight_decay=5e-4.pth')

# Print Model Summary
model3 = Net2()
to_device(model3, 'cuda')
summary(model3, (3,84,84))

# train model
f = open("model2_weight_decay=5e-6.txt", "w")
num_epochs = 50
history3 = fit(num_epochs, model3, train_loader, test_loader, f=f, weight_decay=5e-6)
f.close()
torch.save(model3.state_dict(), 'model2_weight_decay=5e-6.pth')

# plot graphs

# collect data
train_acc1 = []
test_acc1 = []
train_loss1 = []
test_loss1 = []
for i in range(len(history1)):
  train_acc1.append(history1[i]['train_acc'])
  test_acc1.append(history1[i]['val_acc'])
  train_loss1.append(history1[i]['train_loss'])
  test_loss1.append(history1[i]['val_loss'])

train_acc2 = []
test_acc2 = []
train_loss2 = []
test_loss2 = []
for i in range(len(history2)):
  train_acc2.append(history2[i]['train_acc'])
  test_acc2.append(history2[i]['val_acc'])
  train_loss2.append(history2[i]['train_loss'])
  test_loss2.append(history2[i]['val_loss'])

train_acc3 = []
test_acc3 = []
train_loss3 = []
test_loss3 = []
for i in range(len(history3)):
  train_acc3.append(history3[i]['train_acc'])
  test_acc3.append(history3[i]['val_acc'])
  train_loss3.append(history3[i]['train_loss'])
  test_loss3.append(history3[i]['val_loss'])

# Plot accuracy vs epochs
fig=plt.figure(figsize=(5,5))
plt.plot(train_acc1,'b')
plt.plot(train_acc2,'g')
plt.plot(train_acc3,'r')
plt.plot(test_acc1,'b',linestyle='-.')
plt.plot(test_acc2,'g',linestyle='-.')
plt.plot(test_acc3,'r',linestyle='-.')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['5e-2_train','5e-4_train','5e-6_train','5e-2_test','5e-4_test','5e-6_test'])
fig.savefig('Weight decay comparison Accuracy vs Epochs plot.jpg')

# Plot accuracy vs epochs
fig=plt.figure(figsize=(5,5))
plt.plot(train_loss1,'b')
plt.plot(train_loss2,'g')
plt.plot(train_loss3,'r')
plt.plot(test_loss1,'b',linestyle='-.')
plt.plot(test_loss2,'g',linestyle='-.')
plt.plot(test_loss3,'r',linestyle='-.')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['5e-2_train','5e-4_train','5e-6_train','5e-2_test','5e-4_test','5e-6_test'])
fig.savefig('Weight decay comparison Loss vs Epochs plot.jpg')



